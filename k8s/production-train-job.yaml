apiVersion: batch/v1
kind: Job
metadata:
  name: ${JOB_NAME}
spec:
  completions: 1
  parallelism: 1
  ttlSecondsAfterFinished: 1200
  backoffLimit: 0
  template:
    spec:
      serviceAccountName: ${K8S_SERVICE_ACCOUNT}
      containers:
      - name: trainer
        image: ${IMAGE}
        command: ["/bin/sh", "-c"]
        args:
          - |
            set -e
            export GIT_PYTHON_REFRESH=quiet

            echo "[TRAIN-JOB] Step 1/5: Downloading raw data from GCS..."
            python -c "
            from src.train import download_prefix_from_gcs
            from pathlib import Path
            download_prefix_from_gcs('${BUCKET_NAME}', '${DATASET_GCS_PREFIX}', Path('/tmp/raw'))
            "
            echo "[TRAIN-JOB] Raw data downloaded:"
            ls -la /tmp/raw/

            echo "[TRAIN-JOB] Step 2/5: Running ingest (normalize folder names)..."
            python src/ingest.py --source-dir /tmp/raw --output-dir /tmp/ingested
            echo "[TRAIN-JOB] Uploading ingested data to GCS (versioned)..."
            python -c "
            from src.train import upload_directory_to_gcs
            from pathlib import Path
            upload_directory_to_gcs('${BUCKET_NAME}', Path('/tmp/ingested'), '${DATA_VERSION_PREFIX}/ingested')
            "
            echo "[TRAIN-JOB] Ingested data versioned at gs://${BUCKET_NAME}/${DATA_VERSION_PREFIX}/ingested/"

            echo "[TRAIN-JOB] Step 3/5: Running preprocessing (resize + split)..."
            python src/preprocessing.py --input-dir /tmp/ingested --output-dir /tmp/processed
            echo "[TRAIN-JOB] Uploading processed data to GCS (versioned)..."
            python -c "
            from src.train import upload_directory_to_gcs
            from pathlib import Path
            upload_directory_to_gcs('${BUCKET_NAME}', Path('/tmp/processed'), '${DATA_VERSION_PREFIX}/processed')
            "
            echo "[TRAIN-JOB] Processed data versioned at gs://${BUCKET_NAME}/${DATA_VERSION_PREFIX}/processed/"

            echo "[TRAIN-JOB] Step 4/5: Running EDA..."
            python src/eda.py --data-dir /tmp/processed --output /tmp/artifacts/eda/class_balance.png
            python -c "
            from src.train import upload_file_to_gcs
            from pathlib import Path
            upload_file_to_gcs('${BUCKET_NAME}', Path('/tmp/artifacts/eda/class_balance.png'), '${DATA_VERSION_PREFIX}/eda/class_balance.png')
            "
            echo "[TRAIN-JOB] EDA artifact at gs://${BUCKET_NAME}/${DATA_VERSION_PREFIX}/eda/class_balance.png"

            echo "[TRAIN-JOB] Step 4/5: Training model..."
            python src/train.py \
              --data-dir=/tmp/processed \
              --output-model=/tmp/model.pt \
              --artifact-dir=/tmp/artifacts \
              --bucket=${BUCKET_NAME} \
              --model-gcs-prefix=${MODEL_GCS_PREFIX} \
              --epochs=${EPOCHS} \
              --batch-size=${BATCH_SIZE} \
              --learning-rate=${LEARNING_RATE} \
              --model-variant=${MODEL_VARIANT} \
              --num-workers=2 \
              --git-sha=${GIT_SHA} \
              --mlflow-tracking-uri=http://mlflow-service.${K8S_NAMESPACE}.svc.cluster.local:5000

            echo "[TRAIN-JOB] Pipeline complete"
            echo "[TRAIN-JOB] Data lineage for this run:"
            echo "  Raw:       gs://${BUCKET_NAME}/${DATASET_GCS_PREFIX}/"
            echo "  Ingested:  gs://${BUCKET_NAME}/${DATA_VERSION_PREFIX}/ingested/"
            echo "  Processed: gs://${BUCKET_NAME}/${DATA_VERSION_PREFIX}/processed/"
            echo "  Model:     gs://${BUCKET_NAME}/${MODEL_GCS_PREFIX}/model.pt"
        volumeMounts:
        - name: dshm
          mountPath: /dev/shm
        resources:
          requests:
            cpu: "2500m"
            memory: "10Gi"
          limits:
            cpu: "3500m"
            memory: "12Gi"
      restartPolicy: Never
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 1Gi
